{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e70657a4",
   "metadata": {},
   "source": [
    "# Task 2 — The Prober (Activation Maximization)\n",
    "\n",
    "> Followed per instructions.md: load trained model, evaluate train/test, and visualize internal features with activation maximization.\n",
    "\n",
    "**Note:** This notebook prints many 10×10 grids for insight. It can take time to run end-to-end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5e5da3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Paths:\n",
      " - DATA_ROOT: ../task0/outputs/colored-mnist\n",
      " - WEIGHTS_PATH: ../task1/saved_models/cnn_weights_feb1_GODLYPULL.pth\n"
     ]
    }
   ],
   "source": [
    "# === Phase 0: Setup ===\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "SEED = 1337\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Paths\n",
    "DATA_ROOT = Path(\"../task0/outputs/colored-mnist\")\n",
    "WEIGHTS_PATH = Path(\"../task1/saved_models/cnn_weights_feb1_GODLYPULL.pth\")\n",
    "\n",
    "# Hyperparams for visualization (adjust if needed)\n",
    "GRID_SIZE = 10  # 10x10 grids\n",
    "GRID_STEPS = 50\n",
    "GRID_LR = 0.05\n",
    "POLY_STEPS = 60\n",
    "POLY_LR = 0.05\n",
    "SINGLE_NEURON_STEPS = 60\n",
    "SINGLE_NEURON_LR = 0.05\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "print(\"Paths:\")\n",
    "print(\" - DATA_ROOT:\", DATA_ROOT)\n",
    "print(\" - WEIGHTS_PATH:\", WEIGHTS_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822970a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded weights.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === Model (must match ../task1/cnn.ipynb) ===\n",
    "conv1_features = 8\n",
    "conv2_features = 16\n",
    "\n",
    "class ThreeLayerCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, conv1_features, kernel_size=5, padding=\"same\")\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(conv1_features, conv2_features, kernel_size=5, padding=\"same\")\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(conv2_features * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        self.relu_fc = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.relu1(self.conv1(x)))\n",
    "        x = self.pool2(self.relu2(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu_fc(self.fc1(x))\n",
    "        x = self.relu_fc(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "model = ThreeLayerCNN().to(device)\n",
    "\n",
    "if not WEIGHTS_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Weights not found: {WEIGHTS_PATH}\")\n",
    "\n",
    "state = torch.load(WEIGHTS_PATH, map_location=device)\n",
    "model.load_state_dict(state)\n",
    "model.eval()\n",
    "\n",
    "# freeze weights explicitly\n",
    "for p in model.parameters():\n",
    "    p.requires_grad_(False)\n",
    "\n",
    "print(\"Loaded weights.\")\n",
    "\n",
    "\n",
    "# === Dataset ===\n",
    "BASE_TRANSFORM = transforms.ToTensor()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ef00c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_meta(split: str) -> pd.DataFrame:\n",
    "    path = DATA_ROOT / split / \"labels.csv\"\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"{path} not found. Run generation first.\")\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "def _load_rgb(split: str, filename: str) -> torch.Tensor:\n",
    "    path = DATA_ROOT / split / \"images\" / filename\n",
    "    return BASE_TRANSFORM(Image.open(path).convert(\"RGB\"))\n",
    "\n",
    "class ColoredMNISTDataset(Dataset):\n",
    "    def __init__(self, split: str):\n",
    "        assert split in {\"train\", \"test\"}\n",
    "        self.split = split\n",
    "        self.meta = load_meta(split)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.meta.iloc[idx]\n",
    "        img = _load_rgb(self.split, row.filename)\n",
    "        label = int(row.label)\n",
    "        return img, label\n",
    "\n",
    "train_dataset = ColoredMNISTDataset(\"train\")\n",
    "test_dataset = ColoredMNISTDataset(\"test\")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e923696",
   "metadata": {},
   "outputs": [
    {
     "ename": "_IncompleteInputError",
     "evalue": "incomplete input (808344353.py, line 20)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef _apply_jitter(img: torch.Tensor, jitter: int) -> torch.Tensor:\u001b[39m\n                                                                      ^\n\u001b[31m_IncompleteInputError\u001b[39m\u001b[31m:\u001b[39m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def evaluate(loader, name: str) -> float:\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    for images, labels in loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        logits = model(images)\n",
    "        preds = logits.argmax(dim=1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    acc = 100.0 * correct / max(total, 1)\n",
    "    print(f\"{name} Accuracy: {acc:.2f}%\")\n",
    "    return acc\n",
    "\n",
    "print(\"Evaluating train/test accuracy...\")\n",
    "train_acc = evaluate(train_loader, \"Train\")\n",
    "test_acc = evaluate(test_loader, \"Test\")\n",
    "\n",
    "\n",
    "# === Helpers for activation maximization ===\n",
    "def _apply_jitter(img: torch.Tensor, jitter: int) -> torch.Tensor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89d15e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    if jitter <= 0:\n",
    "        return img\n",
    "    ox = random.randint(-jitter, jitter)\n",
    "    oy = random.randint(-jitter, jitter)\n",
    "    return torch.roll(img, shifts=(ox, oy), dims=(2, 3))\n",
    "\n",
    "def _apply_blur(img: torch.Tensor, k: int) -> torch.Tensor:\n",
    "    if k <= 1:\n",
    "        return img\n",
    "    if k % 2 == 0:\n",
    "        k += 1\n",
    "    return F.avg_pool2d(img, kernel_size=k, stride=1, padding=k // 2)\n",
    "\n",
    "def maximize_channel(\n",
    "    model: nn.Module,\n",
    "    layer: nn.Module,\n",
    "    channel: int,\n",
    "    *,\n",
    "    steps: int = 200,\n",
    "    lr: float = 0.05,\n",
    "    color_penalty: float = 0.0,\n",
    "    jitter: int = 0,\n",
    "    blur_k: int = 0,\n",
    "    seed: int | None = None,\n",
    "    clamp: bool = True,\n",
    "    ) -> torch.Tensor:\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    activations: Dict[str, torch.Tensor] = {}\n",
    "    def hook(_, __, output):\n",
    "        activations[\"feat\"] = output\n",
    "\n",
    "    handle = layer.register_forward_hook(hook)\n",
    "    img = torch.randn(1, 3, 28, 28, device=device, requires_grad=True)\n",
    "    opt = torch.optim.Adam([img], lr=lr)\n",
    "\n",
    "    for _ in range(steps):\n",
    "        opt.zero_grad()\n",
    "        inp = _apply_jitter(img, jitter)\n",
    "        inp = _apply_blur(inp, blur_k)\n",
    "        model(inp)\n",
    "        feat = activations[\"feat\"]\n",
    "        act = feat[:, channel].mean()\n",
    "        color_var = img.std(dim=(2, 3)).mean()\n",
    "        loss = -act + (color_penalty * color_var)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if clamp:\n",
    "            img.data.clamp_(0, 1)\n",
    "\n",
    "    handle.remove()\n",
    "    return img.detach().cpu()\n",
    "\n",
    "def maximize_fc_neuron(\n",
    "    model: nn.Module,\n",
    "    layer: nn.Module,\n",
    "    neuron: int,\n",
    "    *,\n",
    "    steps: int = 200,\n",
    "    lr: float = 0.05,\n",
    "    jitter: int = 0,\n",
    "    blur_k: int = 0,\n",
    "    seed: int | None = None,\n",
    "    clamp: bool = True,\n",
    "    ) -> torch.Tensor:\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    activations: Dict[str, torch.Tensor] = {}\n",
    "    def hook(_, __, output):\n",
    "        activations[\"feat\"] = output\n",
    "\n",
    "    handle = layer.register_forward_hook(hook)\n",
    "    img = torch.randn(1, 3, 28, 28, device=device, requires_grad=True)\n",
    "    opt = torch.optim.Adam([img], lr=lr)\n",
    "\n",
    "    for _ in range(steps):\n",
    "        opt.zero_grad()\n",
    "        inp = _apply_jitter(img, jitter)\n",
    "        inp = _apply_blur(inp, blur_k)\n",
    "        model(inp)\n",
    "        feat = activations[\"feat\"]\n",
    "        act = feat[:, neuron].mean()\n",
    "        loss = -act\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if clamp:\n",
    "            img.data.clamp_(0, 1)\n",
    "\n",
    "    handle.remove()\n",
    "    return img.detach().cpu()\n",
    "\n",
    "def maximize_spatial_neuron(\n",
    "    model: nn.Module,\n",
    "    layer: nn.Module,\n",
    "    channel: int,\n",
    "    y: int,\n",
    "    x: int,\n",
    "    *,\n",
    "    steps: int = 200,\n",
    "    lr: float = 0.05,\n",
    "    seed: int | None = None,\n",
    "    clamp: bool = True,\n",
    "    ) -> torch.Tensor:\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    activations: Dict[str, torch.Tensor] = {}\n",
    "    def hook(_, __, output):\n",
    "        activations[\"feat\"] = output\n",
    "\n",
    "    handle = layer.register_forward_hook(hook)\n",
    "    img = torch.randn(1, 3, 28, 28, device=device, requires_grad=True)\n",
    "    opt = torch.optim.Adam([img], lr=lr)\n",
    "\n",
    "    for _ in range(steps):\n",
    "        opt.zero_grad()\n",
    "        model(img)\n",
    "        feat = activations[\"feat\"]\n",
    "        act = feat[0, channel, y, x]\n",
    "        loss = -act\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        if clamp:\n",
    "            img.data.clamp_(0, 1)\n",
    "\n",
    "    handle.remove()\n",
    "    return img.detach().cpu()\n",
    "\n",
    "def plot_grid(images: List[torch.Tensor], title: str):\n",
    "    assert len(images) == GRID_SIZE * GRID_SIZE\n",
    "    grid = make_grid(torch.cat(images, dim=0), nrow=GRID_SIZE, padding=2)\n",
    "    np_img = grid.permute(1, 2, 0).numpy()\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.imshow(np_img)\n",
    "    plt.title(title)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def log_template(layer: str, channels: str, objective: str, regularization: str):\n",
    "    print(\"Layer:\", layer)\n",
    "    print(\"Channel/Neuron:\", channels)\n",
    "    print(\"Objective:\", objective)\n",
    "    print(\"Regularization:\", regularization)\n",
    "    print(\"Observation: TODO\")\n",
    "    print(\"Interpretation: TODO\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "# === Phase 2: Early Layer Exploration (conv1) ===\n",
    "print(\"\\n[Phase 2] Early layer exploration: conv1\")\n",
    "conv1 = model.conv1\n",
    "conv2 = model.conv2\n",
    "\n",
    "conv1_channels = [i % conv1_features for i in range(GRID_SIZE * GRID_SIZE)]\n",
    "conv1_images = []\n",
    "for idx, ch in enumerate(conv1_channels):\n",
    "    img = maximize_channel(\n",
    "        model, conv1, ch,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a0e8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "        steps=GRID_STEPS, lr=GRID_LR, seed=SEED + idx\n",
    "    )\n",
    "    conv1_images.append(img)\n",
    "plot_grid(conv1_images, title=\"Conv1 (early) | channel-wise maximization | 10x10 grid\")\n",
    "log_template(\"conv1\", \"channels repeated 0-7\", \"mean activation\", \"none\")\n",
    "\n",
    "\n",
    "# === Phase 3: Channel Survey (conv1 + conv2) ===\n",
    "print(\"\\n[Phase 3] Channel survey: conv1 (100 images)\")\n",
    "conv1_survey_channels = [i % conv1_features for i in range(GRID_SIZE * GRID_SIZE)]\n",
    "conv1_survey_images = []\n",
    "for idx, ch in enumerate(conv1_survey_channels):\n",
    "    img = maximize_channel(\n",
    "        model, conv1, ch,\n",
    "        steps=GRID_STEPS, lr=GRID_LR, seed=SEED + 100 + idx\n",
    "    )\n",
    "    conv1_survey_images.append(img)\n",
    "plot_grid(conv1_survey_images, title=\"Conv1 survey | 10x10 grid\")\n",
    "log_template(\"conv1\", \"channels repeated 0-7\", \"mean activation\", \"none\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5816c180",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n[Phase 3] Channel survey: conv2 (100 images)\")\n",
    "conv2_survey_channels = [i % conv2_features for i in range(GRID_SIZE * GRID_SIZE)]\n",
    "conv2_survey_images = []\n",
    "for idx, ch in enumerate(conv2_survey_channels):\n",
    "    img = maximize_channel(\n",
    "        model, conv2, ch,\n",
    "        steps=GRID_STEPS, lr=GRID_LR, seed=SEED + 200 + idx\n",
    "    )\n",
    "    conv2_survey_images.append(img)\n",
    "plot_grid(conv2_survey_images, title=\"Conv2 survey | 10x10 grid\")\n",
    "log_template(\"conv2\", \"channels repeated 0-15\", \"mean activation\", \"none\")\n",
    "\n",
    "\n",
    "# === Phase 4: FC neuron probing (sampled neurons) ===\n",
    "print(\"\\n[Phase 4] FC neuron probing: fc1 (100 images)\")\n",
    "fc1 = model.fc1\n",
    "fc2 = model.fc2\n",
    "fc3 = model.fc3\n",
    "\n",
    "fc1_neurons = [i % 128 for i in range(GRID_SIZE * GRID_SIZE)]\n",
    "fc1_images = []\n",
    "for idx, n in enumerate(fc1_neurons):\n",
    "    img = maximize_fc_neuron(\n",
    "        model, fc1, n,\n",
    "        steps=GRID_STEPS, lr=GRID_LR, seed=SEED + 300 + idx\n",
    "    )\n",
    "    fc1_images.append(img)\n",
    "plot_grid(fc1_images, title=\"FC1 neuron survey | 10x10 grid\")\n",
    "log_template(\"fc1\", \"neurons repeated 0-127\", \"mean activation\", \"none\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d71021",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Phase 4] FC neuron probing: fc2 (100 images)\")\n",
    "fc2_neurons = [i % 64 for i in range(GRID_SIZE * GRID_SIZE)]\n",
    "fc2_images = []\n",
    "for idx, n in enumerate(fc2_neurons):\n",
    "    img = maximize_fc_neuron(\n",
    "        model, fc2, n,\n",
    "        steps=GRID_STEPS, lr=GRID_LR, seed=SEED + 400 + idx\n",
    "    )\n",
    "    fc2_images.append(img)\n",
    "plot_grid(fc2_images, title=\"FC2 neuron survey | 10x10 grid\")\n",
    "log_template(\"fc2\", \"neurons repeated 0-63\", \"mean activation\", \"none\")\n",
    "\n",
    "print(\"\\n[Phase 4] FC neuron probing: fc3/logits (100 images)\")\n",
    "fc3_neurons = [i % 10 for i in range(GRID_SIZE * GRID_SIZE)]\n",
    "fc3_images = []\n",
    "for idx, n in enumerate(fc3_neurons):\n",
    "    img = maximize_fc_neuron(\n",
    "        model, fc3, n,\n",
    "        steps=GRID_STEPS, lr=GRID_LR, seed=SEED + 500 + idx\n",
    "    )\n",
    "    fc3_images.append(img)\n",
    "plot_grid(fc3_images, title=\"FC3 (logits) neuron survey | 10x10 grid\")\n",
    "log_template(\"fc3\", \"neurons repeated 0-9\", \"mean activation\", \"none\")\n",
    "\n",
    "\n",
    "# === Phase 5: Polysemanticity experiments (critical) ===\n",
    "print(\"\\n[Phase 5] Polysemanticity experiments on conv2 channel 0\")\n",
    "channel_target = 0\n",
    "\n",
    "poly_plain = []\n",
    "poly_color = []\n",
    "poly_jitter_blur = []\n",
    "for idx in range(GRID_SIZE * GRID_SIZE):\n",
    "    poly_plain.append(maximize_channel(\n",
    "        model, conv2, channel_target,\n",
    "        steps=POLY_STEPS, lr=POLY_LR, seed=SEED + 600 + idx\n",
    "    ))\n",
    "    poly_color.append(maximize_channel(\n",
    "        model, conv2, channel_target,\n",
    "        steps=POLY_STEPS, lr=POLY_LR, seed=SEED + 700 + idx, color_penalty=1.0\n",
    "    ))\n",
    "    poly_jitter_blur.append(maximize_channel(\n",
    "        model, conv2, channel_target,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "        steps=POLY_STEPS, lr=POLY_LR, seed=SEED + 800 + idx, jitter=2, blur_k=3\n",
    "    ))\n",
    "\n",
    "plot_grid(poly_plain, title=\"Polysemanticity | conv2 ch0 | plain objective | 10x10\")\n",
    "log_template(\"conv2\", \"channel 0\", \"mean activation\", \"none\")\n",
    "\n",
    "plot_grid(poly_color, title=\"Polysemanticity | conv2 ch0 | + color penalty | 10x10\")\n",
    "log_template(\"conv2\", \"channel 0\", \"mean activation\", \"color variance penalty (lambda=1.0)\")\n",
    "\n",
    "plot_grid(poly_jitter_blur, title=\"Polysemanticity | conv2 ch0 | jitter+blur | 10x10\")\n",
    "log_template(\"conv2\", \"channel 0\", \"mean activation\", \"jitter=2, blur_k=3\")\n",
    "\n",
    "\n",
    "# === Phase 8: Single-neuron probing (spatial specificity) ===\n",
    "print(\"\\n[Phase 8] Single-neuron probing on conv2 channel 0 across spatial positions\")\n",
    "spatial_images = []\n",
    "positions: List[Tuple[int, int]] = []\n",
    "for i in range(GRID_SIZE * GRID_SIZE):\n",
    "    y = i % 7\n",
    "    x = (i // 7) % 7\n",
    "    positions.append((y, x))\n",
    "for idx, (y, x) in enumerate(positions):\n",
    "    img = maximize_spatial_neuron(\n",
    "        model, conv2, channel=0, y=y, x=x,\n",
    "        steps=SINGLE_NEURON_STEPS, lr=SINGLE_NEURON_LR, seed=SEED + 900 + idx\n",
    "    )\n",
    "    spatial_images.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284b166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grid(spatial_images, title=\"Single-neuron probe | conv2 ch0 | varying (y,x) | 10x10\")\n",
    "log_template(\"conv2\", \"channel 0, spatial positions\", \"single neuron activation\", \"none\")\n",
    "\n",
    "\n",
    "# === Phase 6: Cross-layer comparison (same objective, different layers) ===\n",
    "print(\"\\n[Phase 6] Cross-layer comparison for channel 0\")\n",
    "cross_conv1 = []\n",
    "cross_conv2 = []\n",
    "for idx in range(GRID_SIZE * GRID_SIZE):\n",
    "    cross_conv1.append(maximize_channel(\n",
    "        model, conv1, 0, steps=GRID_STEPS, lr=GRID_LR, seed=SEED + 1000 + idx\n",
    "    ))\n",
    "    cross_conv2.append(maximize_channel(\n",
    "        model, conv2, 0, steps=GRID_STEPS, lr=GRID_LR, seed=SEED + 1100 + idx\n",
    "    ))\n",
    "plot_grid(cross_conv1, title=\"Cross-layer | conv1 ch0 | 10x10\")\n",
    "log_template(\"conv1\", \"channel 0\", \"mean activation\", \"none\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfafc1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_grid(cross_conv2, title=\"Cross-layer | conv2 ch0 | 10x10\")\n",
    "log_template(\"conv2\", \"channel 0\", \"mean activation\", \"none\")\n",
    "\n",
    "print(\"\\nDone. Please fill the Observation/Interpretation lines above for each grid.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
